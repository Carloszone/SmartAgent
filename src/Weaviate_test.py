import weaviate
from weaviate.classes.config import Configure, Property, DataType, Vectorizers, Tokenization
from weaviate.classes.query import Filter
from weaviate.classes.query import MetadataQuery
from ConfigManager import config
import json

# --- ç¬¬ä¸€æ­¥ï¼šè¿æ¥åˆ°æ‚¨çš„ Weaviate æœåŠ¡ ---
try:
    client = weaviate.connect_to_local(
        host="localhost",
        port=8080,
        grpc_port=50051
    )
    print("æˆåŠŸè¿æ¥åˆ° Weaviate!")

    # --- ç¬¬äºŒæ­¥ï¼šåˆ é™¤å…¨éƒ¨collections ---
    if client.is_ready(): # is_ready() æ£€æŸ¥è¿æ¥
        client.collections.delete_all()

    # --- ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰æ–° Collection çš„åç§°å’Œå­—æ®µç»“æ„ ---
    embeding_model_name = config.get_setting('models')["text_embedding_model_name"]
    collection_name = "knowledge_base_collection"
    
    properties_to_create = [
        Property(
            name="content",
            description="åŸå§‹æ–‡æœ¬",
            data_type=DataType.TEXT,
            tokenization=Tokenization.GSE,
            index_searchable=True
        ),
        Property(
            name="summary",
            description="åŸå§‹æ–‡æœ¬çš„æ¦‚æ‹¬",
            data_type=DataType.TEXT,
            tokenization=Tokenization.GSE,
            index_searchable=True
        ),
        Property(
            name="questions",
            description="åŸå§‹æ–‡æœ¬çš„æ´¾ç”Ÿé—®é¢˜",
            data_type=DataType.TEXT,
            tokenization=Tokenization.GSE,
            index_searchable=True
        ),
        Property(
            name="source",
            description="æ¥æºæ–‡ä»¶è·¯å¾„æˆ–URL",
            data_type=DataType.TEXT,
            index_filterable=True
        ),
        Property(
            name="file_type",
            description="åŸå§‹æ–‡ä»¶çš„ç±»å‹ (e.g., pdf, docx, md)",
            data_type=DataType.TEXT,
            index_filterable=True
        ),
        Property(
            name="chunk_type",
            description="å†…å®¹å—çš„ç±»å‹ (e.g., pdf, docx, md)",
            data_type=DataType.TEXT,
            index_filterable=True
        ),
        Property(
            name="access_level",
            description="è®¿é—®æ§åˆ¶çº§åˆ«",
            data_type=DataType.INT,
            index_filterable=True
        ),
        # Property(
        #     name="page_number",
        #     description="åœ¨åŸå§‹æ–‡ä»¶ä¸­çš„é¡µç ",
        #     data_type=DataType.INT,
        #     index_filterable=True
        # ),
        Property(
            name="chunk_seq_id",
            description="å†…å®¹å—çš„åºåˆ—ID",
            data_type=DataType.INT,
            index_filterable=True
        ),
    ]


    # --- ç¬¬å››æ­¥ï¼šåˆ›å»ºæ–°çš„ Collection ---
    print(f"\n## æ­£åœ¨åˆ›å»ºæ–°çš„ Collection: '{collection_name}'...")
    client.collections.create(
        name=collection_name,
        vectorizer_config=[
            Configure.NamedVectors.text2vec_ollama(
                name="content_vector",
                source_properties=["content"],
                api_endpoint="http://ollama-host:11434",
                model=embeding_model_name
            ),
            Configure.NamedVectors.text2vec_ollama(
                name="summary_vector",
                source_properties=["summary"],
                api_endpoint="http://ollama-host:11434",
                model=embeding_model_name
            ),
            Configure.NamedVectors.text2vec_ollama(
                name="question_vector",
                source_properties=["questions"],
                api_endpoint="http://ollama-host:11434",
                model=embeding_model_name
            )
        ],
        properties=properties_to_create
    )
    print(f"âœ… Collection '{collection_name}' åˆ›å»ºæˆåŠŸï¼")


    # --- é‡å¤ç¬¬ä¸‰æ­¥å’Œç¬¬å››æ­¥ï¼Œæ„å»ºç¬¬äºŒå¼ è¡¨ ---
    collection_name = "chat_histroy_collection"
    
    properties_to_create = [
        Property(
            name="question",
            description="é—®é¢˜",
            data_type=DataType.TEXT,
            tokenization=Tokenization.GSE,
            index_searchable=True
        ),
        Property(
            name="answer",
            description="å›ç­”",
            data_type=DataType.TEXT,
            tokenization=Tokenization.GSE,
            index_searchable=True
        ),
        Property(
            name="chat_id",
            description="èŠå¤©ä¼šè¯id",
            data_type=DataType.TEXT,
            index_filterable=True
        ),
        Property(
            name="user_id",
            description="å‘èµ·èŠå¤©çš„ç”¨æˆ·çš„id",
            data_type=DataType.TEXT,
            index_filterable=True
        ),
        Property(
            name="access_level",
            description="è®¿é—®æ§åˆ¶çº§åˆ«",
            data_type=DataType.INT,
            index_filterable=True
        ),
        Property(
            name="chunk_seq_id",
            description="æ–‡æœ¬å—åœ¨å…¶æ‰€å±æ–‡æœ¬ä¸­çš„åºåˆ—ID",
            data_type=DataType.INT,
            index_filterable=True
        ),
    ]


    print(f"\n## æ­£åœ¨åˆ›å»ºæ–°çš„ Collection: '{collection_name}'...")
    client.collections.create(
        name=collection_name,
        properties=properties_to_create,
        vectorizer_config=[
            Configure.NamedVectors.text2vec_ollama(
                name="question_vector",
                source_properties=["question"],
                api_endpoint="http://ollama-host:11434",
                model=embeding_model_name
            ),
            Configure.NamedVectors.text2vec_ollama(
                name="answer_vector",
                source_properties=["answer"],
                api_endpoint="http://ollama-host:11434",
                model=embeding_model_name
            )
        ]
    )
    print(f"âœ… Collection '{collection_name}' åˆ›å»ºæˆåŠŸï¼")

    # ---  æŸ¥è¯¢

    # collection = client.collections.get("knowledge_base_collection")
    # config = collection.config.get()
    # print(config.properties)
    # response = collection.query.fetch_objects(
    #     limit=1,
    #     include_vector=True,
    #     return_metadata=MetadataQuery(
    #         creation_time=True,
    #         last_update_time=True,
    #         distance=True,
    #         certainty=True,
    #         score=True
    #     )
    # )
    # print("æŸ¥è¯¢è¿”å›ï¼š")
    # print(response.objects[0])


except Exception as e:
    print(f"\nâŒ æ“ä½œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

    # collection_name = "knowledge_base_collection"
    # document_collection = client.collections.get(collection_name)
    # aggregation_result = document_collection.aggregate.over_all(total_count=True)
    # total = aggregation_result.total_count
    # print(f"\nğŸ“Š æ•°æ®è¡¨ '{collection_name}' çš„æ€»è®°å½•æ•°ä¸º: {total}")

finally:
    # --- æœ€åä¸€æ­¥ï¼šå…³é—­è¿æ¥ ---
    if 'client' in locals() and client.is_connected():
        client.close()
        print("\nè¿æ¥å·²å…³é—­ã€‚")